---
title: When to Use Cortex TMS
description: Decision framework - Is Cortex TMS right for your project? Signs you need it vs. signs you don't
---

import { Card, CardGrid, Tabs, TabItem, Aside, FileTree } from '@astrojs/starlight/components';

You are evaluating Cortex TMS and wondering: **Is this right for my project?**

The answer depends on three factors:
1. **How much do you use AI coding assistants?**
2. **How complex is your architecture?**
3. **How many people need to understand your codebase?**

This guide provides a decision framework to help you determine if Cortex TMS is the right tool for your situation.

---

## Quick Self-Assessment Quiz

Answer these questions honestly. If you answer "yes" to 4 or more, Cortex TMS will provide significant value.

<CardGrid>
  <Card title="1. AI Usage" icon="rocket">
    Do you or your team use AI coding assistants (Claude Code, GitHub Copilot, Cursor, or similar) on a daily basis?
  </Card>

  <Card title="2. AI-Generated Code Quality" icon="warning">
    Do you frequently review AI-generated code and find it works but violates your architectural patterns or conventions?
  </Card>

  <Card title="3. Documentation Drift" icon="error">
    Is your documentation frequently outdated? Do you find yourself explaining "the docs are wrong, we actually do it this way"?
  </Card>

  <Card title="4. Onboarding Friction" icon="information">
    Does onboarding new developers (human or AI) take days or weeks? Do they ask the same questions repeatedly?
  </Card>

  <Card title="5. Pattern Inconsistency" icon="random">
    Do you have the same feature implemented multiple ways across your codebase? (e.g., authentication using 3 different approaches)
  </Card>

  <Card title="6. Lost Context" icon="puzzle">
    When you return to a project after a break, do you spend hours re-learning your own architectural decisions?
  </Card>

  <Card title="7. Architecture Enforcement" icon="approve-check">
    Do you have critical architectural rules that MUST be followed, but they exist only in code reviews, Slack messages, or people's memories?
  </Card>

  <Card title="8. Code Review Burden" icon="seti:todo">
    Do code reviews involve repeatedly explaining the same patterns, conventions, or security practices?
  </Card>

  <Card title="9. Distributed Team" icon="star">
    Does your team work asynchronously across time zones, making real-time knowledge transfer difficult?
  </Card>

  <Card title="10. Open Source Maintainer Burnout" icon="open-book">
    Are you an open source maintainer drowning in PRs that need multiple review rounds due to pattern violations?
  </Card>
</CardGrid>

**Scoring:**
- **7-10 "yes"**: Cortex TMS will significantly improve your workflow
- **4-6 "yes"**: Cortex TMS will provide noticeable value
- **1-3 "yes"**: Cortex TMS might help, but evaluate carefully
- **0 "yes"**: Cortex TMS is probably not necessary right now

<Aside type="tip" title="Pro Tip">
  The single biggest indicator is Question 1 (AI usage). If you use AI coding assistants daily, you almost certainly need TMS, regardless of other factors.
</Aside>

---

## Signs You NEED Cortex TMS

These are strong indicators that Cortex TMS will provide immediate, measurable value.

<CardGrid stagger>
  <Card title="High AI Adoption" icon="rocket">
    **Signal**: Your team uses Claude Code, GitHub Copilot, or Cursor for 40+ percent of code generation.

    **Problem**: AI generates code that works but violates your architecture. You spend hours in code review fixing pattern violations.

    **TMS Solution**: Document patterns in `PATTERNS.md` with canonical examples. AI reads these patterns and generates conformant code on the first try.

    **Impact**: 60-80 percent reduction in pattern-related code review feedback.
  </Card>

  <Card title="AI-Generated PRs That Violate Architecture" icon="warning">
    **Signal**: You regularly merge PRs where the code works but uses the wrong approach (wrong libraries, wrong patterns, wrong conventions).

    **Problem**: AI does not know your architectural decisions. It uses common patterns from the internet, not your project-specific patterns.

    **TMS Solution**: Architecture Decision Records (ADRs) in `docs/adr/` document why you chose approach X over Y. AI reads these and follows your decisions.

    **Impact**: 70+ percent reduction in "this works but we do it differently" code review comments.
  </Card>

  <Card title="Maintainer Burnout from Explaining Same Patterns" icon="error">
    **Signal**: You write the same code review comments repeatedly: "We use RS256, not HS256", "We use Zod for validation", "We never store tokens in localStorage".

    **Problem**: Patterns exist in your head, not in documentation. Every new contributor (human or AI) makes the same mistakes.

    **TMS Solution**: Document patterns once in `PATTERNS.md`. Point contributors and AI agents to the canonical source. Stop repeating yourself.

    **Impact**: 50+ percent reduction in code review time spent on pattern education.
  </Card>

  <Card title="Distributed Async Team" icon="star">
    **Signal**: Your team spans multiple time zones. Real-time communication is rare. Most collaboration is asynchronous (GitHub, Slack, email).

    **Problem**: Knowledge transfer happens in synchronous conversations (Zoom calls, hallway chats). Async contributors lack context.

    **TMS Solution**: Single source of truth in repository. Contributors read `ARCHITECTURE.md`, `PATTERNS.md`, `NEXT-TASKS.md` instead of waiting for Zoom calls.

    **Impact**: 10x faster onboarding for async contributors (hours vs. days).
  </Card>

  <Card title="Open Source with AI-Powered Contributors" icon="open-book">
    **Signal**: You maintain an open source project. Contributors are increasingly using AI to generate PRs. Quality varies wildly.

    **Problem**: You cannot control what AI tools contributors use, but you can control what those AI tools read.

    **TMS Solution**: Provide structured governance files (`PATTERNS.md`, `CONTRIBUTING.md`, `.github/copilot-instructions.md`). Contributors' AI agents read these and generate higher-quality PRs.

    **Impact**: 40+ percent reduction in "needs changes" PR labels. Faster merge times.
  </Card>

  <Card title="Frequent Context-Switching Between Projects" icon="puzzle">
    **Signal**: You work on multiple projects. You return to a codebase after weeks or months away. You spend hours re-learning your own decisions.

    **Problem**: Your brain is not a perfect long-term memory system. You forget why you made certain architectural choices.

    **TMS Solution**: `NEXT-TASKS.md` tells you what you were working on. ADRs tell you why you made decisions. You regain context in minutes instead of hours.

    **Impact**: 80+ percent reduction in context-switching penalty (5 minutes vs. 60 minutes).
  </Card>

  <Card title="Critical Security or Compliance Rules" icon="approve-check">
    **Signal**: You have security or compliance requirements that MUST be followed (e.g., "never store PII in logs", "always use HTTPS", "encrypt all database fields with SSN").

    **Problem**: These rules are advisory in traditional docs. Developers (human or AI) can accidentally violate them.

    **TMS Solution**: Document critical rules in `.github/copilot-instructions.md` (HOT tier, always loaded). AI agents prioritize content labeled as critical or security-related. Validation in CI/CD enforces compliance.

    **Impact**: Near-zero critical violations (down from 1-3 per month).
  </Card>

  <Card title="Rapid Scaling or Hiring" icon="setting">
    **Signal**: You are hiring aggressively. You need new developers to become productive in days, not weeks.

    **Problem**: Onboarding requires senior developers to explain architecture, patterns, and conventions repeatedly. This does not scale.

    **TMS Solution**: New developers read HOT tier (`NEXT-TASKS.md`, `CLAUDE.md`) to understand current work, then reference WARM tier (`PATTERNS.md`, `ARCHITECTURE.md`) on demand. AI agents can answer their questions based on documented patterns.

    **Impact**: Onboarding time reduced from 2-4 weeks to 2-4 days.
  </Card>

  <Card title="Monorepo with Multiple Teams" icon="random">
    **Signal**: You have a monorepo with 5+ teams. Each team uses slightly different patterns. Cross-team contributions are painful.

    **Problem**: No shared governance. Team A uses approach X, Team B uses approach Y. Integration is a nightmare.

    **TMS Solution**: Single shared `PATTERNS.md` at monorepo root. All teams follow same patterns. Per-package patterns in subdirectories as needed.

    **Impact**: 60+ percent reduction in cross-team integration bugs.
  </Card>

  <Card title="Technical Debt Accumulation" icon="information">
    **Signal**: Your codebase is growing fast. You ship features quickly but realize you are accumulating technical debt. Refactoring is getting harder.

    **Problem**: No documented patterns means every developer (human or AI) implements features differently. Inconsistency compounds over time.

    **TMS Solution**: Document patterns as you go. Enforce them via validation. Prevent inconsistency from accumulating.

    **Impact**: 40+ percent reduction in refactoring effort (preventative vs. corrective).
  </Card>
</CardGrid>

<Aside type="note">
  If you see yourself in 3 or more of these scenarios, Cortex TMS is almost certainly a good fit. The ROI will be measurable within weeks.
</Aside>

---

## Signs You DON'T Need Cortex TMS

Be honest about when TMS adds overhead without proportional value. These are scenarios where traditional documentation is sufficient.

<CardGrid stagger>
  <Card title="Solo Hobby Project" icon="star">
    **Signal**: You are building a personal project with no collaborators. You have no plans to open source it or hire help.

    **Reality**: TMS optimizes for knowledge transfer between people (human or AI). If you are the only person who will ever touch the code, a simple README is enough.

    **Alternative**: Keep a TODO.md for personal task tracking. Skip TMS until you add collaborators.
  </Card>

  <Card title="No AI Tooling" icon="information">
    **Signal**: Your team does not use AI coding assistants. You are not using Claude Code, Copilot, Cursor, or similar tools.

    **Reality**: TMS optimizes documentation for machine readers (AI agents). If you have no machine readers, the structured format adds overhead without benefit.

    **Alternative**: Traditional documentation (README, wiki, CONTRIBUTING.md) works fine for human-only teams.
  </Card>

  <Card title="Read-Only Codebase" icon="document">
    **Signal**: Your project is in maintenance mode. No active development. Only critical bug fixes.

    **Reality**: TMS prevents documentation drift during active development. If development has stopped, drift is not a concern.

    **Alternative**: Keep existing documentation as-is. No need to restructure for a codebase that is not evolving.
  </Card>

  <Card title="Extremely Small Team (Under 3 People with Daily Standups)" icon="group">
    **Signal**: You have 2-3 developers who talk every day. Everyone knows the entire system. Context fits in human memory.

    **Reality**: TMS optimizes for async knowledge transfer. If your team has synchronous communication and shared context, the overhead may not be justified.

    **Alternative**: Informal documentation (README, wiki) plus daily communication. Add TMS when team grows beyond 3-5 people.
  </Card>

  <Card title="Trivial or Short-Lived Project" icon="seti:todo">
    **Signal**: Your project is a proof-of-concept, hackathon project, or throwaway prototype. Expected lifespan under 1 month.

    **Reality**: TMS pays off over time as documentation prevents drift and enforces patterns. Short-lived projects do not accumulate enough drift to justify the setup.

    **Alternative**: Quick README with getting started instructions. Skip governance.
  </Card>

  <Card title="Highly Regulated Industries with Specific Doc Formats" icon="approve-check">
    **Signal**: Your industry requires documentation in specific formats (ISO standards, FDA compliance, SOC 2 evidence). You need Word docs, PDFs, or proprietary systems.

    **Reality**: TMS uses Markdown files optimized for developer workflows. If you need formal documentation in regulated formats, TMS may not meet compliance requirements.

    **Alternative**: Use required compliance tools. Consider TMS for internal developer documentation alongside formal compliance docs.
  </Card>

  <Card title="Simple CRUD Application" icon="setting">
    **Signal**: Your application is a straightforward CRUD app (create, read, update, delete). No complex business logic. No unusual architectural decisions.

    **Reality**: TMS documents non-obvious patterns and decisions. If your patterns are conventional (follow framework defaults), there is not much to document.

    **Alternative**: Framework-specific documentation (Next.js docs, Rails guides) is sufficient. Add TMS only if you deviate from framework conventions.
  </Card>

  <Card title="Team Philosophically Opposed to AI" icon="warning">
    **Signal**: Your team has decided not to use AI coding assistants for policy, security, or philosophical reasons.

    **Reality**: While TMS provides value for human onboarding and documentation validation, the primary ROI comes from AI governance. Without AI usage, the ROI is lower.

    **Alternative**: Traditional documentation with strong code review processes. Evaluate TMS if you reconsider AI adoption later.
  </Card>
</CardGrid>

<Aside type="tip" title="Pro Tip">
  "You don't need TMS" does not mean TMS would not work. It means the overhead-to-benefit ratio is not favorable. If your situation changes (team grows, add AI tools, complexity increases), reevaluate.
</Aside>

---

## Decision Matrix: Team Size + AI Usage

Use this matrix to determine if Cortex TMS is right for your project based on two key factors: **team size** and **AI usage intensity**.

| Team Size | No AI Usage | Light AI Usage (10-30%) | Heavy AI Usage (40%+) |
|:----------|:------------|:-------------------------|:----------------------|
| **Solo** | ❌ Not needed (README is enough) | ⚠️ Consider (helps context-switching) | ✅ Recommended (prevents AI drift) |
| **2-3 people** | ❌ Not needed (daily standups work) | ⚠️ Consider (reduces repeat explanations) | ✅ Recommended (enforces consistency) |
| **4-10 people** | ⚠️ Consider (helps onboarding) | ✅ Recommended (governance + onboarding) | ✅ Strongly recommended (critical for consistency) |
| **11-50 people** | ✅ Recommended (async knowledge transfer) | ✅ Strongly recommended (mandatory governance) | ✅ Critical (cannot scale without it) |
| **51+ people** | ✅ Strongly recommended (essential at scale) | ✅ Critical (chaos without governance) | ✅ Critical (absolute necessity) |

**Legend:**
- ❌ Not needed: TMS adds overhead without proportional benefit
- ⚠️ Consider: TMS provides value but evaluate ROI carefully
- ✅ Recommended: TMS provides clear value, ROI is positive
- ✅ Strongly recommended: TMS provides high value, ROI is very positive
- ✅ Critical: TMS is essential, project will struggle without it

**AI Usage Definition:**
- **No AI Usage**: Team does not use AI coding assistants
- **Light AI Usage (10-30%)**: Occasional autocomplete, simple functions
- **Heavy AI Usage (40%+)**: AI generates significant portions of code, used for complex features

<Aside type="note">
  The matrix shows general guidelines. Your specific situation may vary. Use the self-assessment quiz and signs sections for a more nuanced evaluation.
</Aside>

---

## Project Lifecycle: When to Adopt

Cortex TMS provides different value at different stages of a project's lifecycle.

### Stage 1: Initial Development (Weeks 1-8)

**Should you adopt TMS?** ⚠️ Maybe (depends on AI usage)

**Characteristics:**
- Exploring architecture
- Experimenting with patterns
- Rapid iteration
- Small codebase (under 5,000 lines)

**TMS Value at This Stage:**
- **Low** if solo: Patterns are not yet established
- **Medium** if team: Helps align on initial patterns
- **High** if heavy AI usage: Prevents early drift

**Recommendation:**
- **Solo + no AI**: Skip TMS, use simple README
- **Solo + AI**: Consider minimal TMS (NEXT-TASKS.md, CLAUDE.md only)
- **Team (2+)**: Adopt TMS early to establish governance from day one

<Aside type="tip" title="Pro Tip">
  If you are unsure, start with just `NEXT-TASKS.md` and `CLAUDE.md`. Add other files as patterns emerge. You do not need the full TMS structure on day one.
</Aside>

---

### Stage 2: Growth Phase (Months 3-12)

**Should you adopt TMS?** ✅ Yes (if using AI or growing team)

**Characteristics:**
- Patterns are stabilizing
- Codebase growing (5,000-50,000 lines)
- Adding team members
- Increased AI usage for productivity

**TMS Value at This Stage:**
- **High**: Patterns are established and need enforcement
- **Onboarding**: New developers need to learn conventions fast
- **Consistency**: Multiple contributors need governance

**Recommendation:**
- **Adopt TMS before team grows beyond 5 people**
- Document established patterns in `PATTERNS.md`
- Create ADRs for major architectural decisions
- Configure AI agents with `CLAUDE.md` / `.github/copilot-instructions.md`

**Time Investment:**
- Initial setup: 2-4 hours
- Ongoing maintenance: 30 minutes per week

**ROI:**
- Pays back setup time within 2-4 weeks (via reduced code review time)

---

### Stage 3: Maturity (Year 2+)

**Should you adopt TMS?** ✅ Strongly recommended (almost always)

**Characteristics:**
- Large codebase (50,000+ lines)
- Distributed team (5+ developers)
- Complex architecture
- Heavy AI usage (40%+ of code)
- Open source with external contributors

**TMS Value at This Stage:**
- **Critical**: Cannot scale without governance
- **Documentation Drift**: Traditional docs are already stale
- **Onboarding Burden**: New developers take weeks to onboard
- **Pattern Divergence**: Same feature implemented 3 different ways

**Recommendation:**
- **Migrate to TMS as soon as possible**
- Follow the migration path in "vs. Traditional Documentation"
- Prioritize documenting critical patterns and security rules
- Enable validation in CI/CD to prevent further drift

**Time Investment:**
- Initial migration: 1-2 weeks (incremental)
- Ongoing maintenance: 1 hour per week

**ROI:**
- Pays back migration time within 1-2 months (via reduced onboarding time, fewer bugs, faster code review)

---

### Stage 4: Maintenance Mode

**Should you adopt TMS?** ⚠️ Maybe (probably not worth it)

**Characteristics:**
- No active feature development
- Only critical bug fixes
- Small team or solo maintainer
- Codebase is stable

**TMS Value at This Stage:**
- **Low**: Documentation drift is not a concern if code is not changing
- **Medium** if you plan to resume development later

**Recommendation:**
- **Skip TMS** if truly in permanent maintenance mode
- **Consider TMS** if you might resume active development in the future (prevents knowledge loss)

---

## Cost-Benefit Analysis

### Time Investment

**Initial Setup** (one-time):
- Run `npx cortex-tms init`: 5 minutes
- Fill in `NEXT-TASKS.md`: 15 minutes
- Document 3-5 key patterns in `PATTERNS.md`: 1-2 hours
- Create `ARCHITECTURE.md`: 30-60 minutes
- Configure AI agent workflow (`CLAUDE.md`): 15 minutes

**Total initial investment: 3-4 hours**

---

**Ongoing Maintenance** (weekly):
- Update `NEXT-TASKS.md` as tasks complete: 10 minutes
- Add new patterns to `PATTERNS.md` as they emerge: 20 minutes (occasional)
- Archive completed tasks to `docs/archive/`: 5 minutes
- Run `cortex-tms validate` in CI/CD: 0 minutes (automated)

**Total weekly investment: 15-20 minutes**

---

### Benefits (Measurable)

**Code Review Time** (saved):
- Before TMS: 60 minutes per PR (average)
  - 20 minutes reviewing logic
  - 40 minutes explaining patterns and requesting changes
- After TMS: 25 minutes per PR (average)
  - 20 minutes reviewing logic
  - 5 minutes verifying pattern compliance (AI already followed patterns)

**Time saved per PR: 35 minutes**

**If you review 10 PRs per week:**
- Time saved: 350 minutes (5.8 hours) per week
- ROI: Pays back setup time in week 1

---

**Onboarding Time** (saved):
- Before TMS: 2-4 weeks (new developer)
  - 1 week reading codebase
  - 1-2 weeks asking questions, learning patterns
  - 1 week first meaningful contribution
- After TMS: 3-5 days (new developer)
  - 1 day reading HOT tier (`NEXT-TASKS.md`, `CLAUDE.md`)
  - 1-2 days referencing WARM tier (`PATTERNS.md`, `ARCHITECTURE.md`)
  - 1-2 days first meaningful contribution

**Time saved per new hire: 2-3 weeks (80-120 hours)**

**If you hire 2 developers per year:**
- Time saved: 160-240 hours per year
- Senior developer time (onboarding mentor): 40-80 hours saved per year

---

**Bug Reduction** (prevented):
- Before TMS: 3-5 pattern-violation bugs per month
  - Wrong authentication approach (1-2 bugs)
  - Inconsistent error handling (1-2 bugs)
  - Security issues (localStorage tokens, missing validation) (1 bug)
- After TMS: 0-1 pattern-violation bugs per month

**Bugs prevented: 3-4 per month**

**Time per bug fix:**
- Discovery: 30 minutes
- Debugging: 60 minutes
- Fix: 30 minutes
- Testing: 30 minutes
- Deployment: 15 minutes

**Total: 2.5 hours per bug**

**Time saved: 7.5-10 hours per month (90-120 hours per year)**

---

**Context-Switching Penalty** (saved):
- Before TMS: 60 minutes to regain context after 1-week break
  - Re-reading code: 30 minutes
  - Remembering why decisions were made: 20 minutes
  - Finding TODO comments: 10 minutes
- After TMS: 5 minutes to regain context
  - Read `NEXT-TASKS.md`: 2 minutes
  - Ask AI: "Summarize current sprint": 3 minutes

**Time saved per context switch: 55 minutes**

**If you context-switch 4 times per month:**
- Time saved: 220 minutes (3.7 hours) per month (44 hours per year)

---

### Total ROI (Annual)

**Costs:**
- Initial setup: 3-4 hours (one-time)
- Ongoing maintenance: 15-20 minutes per week × 52 weeks = 13-17 hours per year

**Total cost: 16-21 hours per year**

---

**Benefits:**
- Code review time saved: 5.8 hours per week × 52 weeks = 302 hours per year
- Onboarding time saved: 160-240 hours per year (if you hire 2 developers)
- Bug prevention time saved: 90-120 hours per year
- Context-switching saved: 44 hours per year

**Total benefit: 596-706 hours per year**

---

**ROI Ratio: 28-42x**

**For every 1 hour invested in TMS, you save 28-42 hours.**

<Aside type="note">
  These numbers are conservative estimates based on teams with 4-10 developers and heavy AI usage. Solo developers will see lower absolute hours saved but similar proportional ROI.
</Aside>

---

## Getting Started If You Are Ready

You have evaluated the decision framework and determined Cortex TMS is right for your project. Here is how to get started.

### Step 1: Install Cortex TMS CLI (2 minutes)

```bash
npx cortex-tms init
```

**What this does:**
- Prompts you to select templates (NEXT-TASKS.md, PATTERNS.md, ARCHITECTURE.md, etc.)
- Scaffolds the HOT/WARM/COLD directory structure
- Creates template files with examples

**Decision:** Which templates to generate?

<Tabs>
  <TabItem label="Minimal (Solo Developer)">
    **Select:**
    - ✅ NEXT-TASKS.md (current work)
    - ✅ CLAUDE.md (AI workflow)

    **Skip:**
    - ❌ PATTERNS.md (add later when patterns emerge)
    - ❌ ARCHITECTURE.md (add later when architecture stabilizes)
    - ❌ GLOSSARY.md (add only if complex domain)

    **Time investment: 30 minutes to fill in templates**
  </TabItem>

  <TabItem label="Standard (Small Team)">
    **Select:**
    - ✅ NEXT-TASKS.md (current sprint)
    - ✅ CLAUDE.md (AI workflow)
    - ✅ PATTERNS.md (code conventions)
    - ✅ ARCHITECTURE.md (tech stack decisions)

    **Skip:**
    - ❌ GLOSSARY.md (add only if needed)

    **Time investment: 2-3 hours to fill in templates**
  </TabItem>

  <TabItem label="Complete (Large Team / Open Source)">
    **Select:**
    - ✅ NEXT-TASKS.md (current sprint)
    - ✅ CLAUDE.md (AI workflow)
    - ✅ PATTERNS.md (code conventions)
    - ✅ ARCHITECTURE.md (tech stack decisions)
    - ✅ GLOSSARY.md (domain terminology)
    - ✅ docs/adr/ (architectural decision records)

    **Time investment: 4-6 hours to fill in templates**
  </TabItem>
</Tabs>

---

### Step 2: Document Current Sprint (15 minutes)

Edit `NEXT-TASKS.md`:

```markdown
# NEXT: Upcoming Tasks

## Active Sprint: [Your current work]

**Why this matters**: [Why this sprint matters to the project]

| Task | Effort | Priority | Status |
| :--- | :----- | :------- | :----- |
| [Current task 1] | [estimate] | HIGH | In Progress |
| [Current task 2] | [estimate] | MEDIUM | Todo |

## Definition of Done

- [Acceptance criteria]
```

**Source:**
- GitHub issues labeled "in progress"
- Your TODO comments
- Your mental task list

---

### Step 3: Document 3-5 Key Patterns (1-2 hours)

Edit `docs/core/PATTERNS.md`:

For each pattern:
1. Find your best example in the codebase
2. Document it as "Canonical Example"
3. List critical rules

**Example:**

```markdown
## Authentication Pattern

**Canonical Example**: `src/middleware/auth.ts`

### Structure

[Describe the pattern]

### Code Template

[Show the code]

**Critical Rules**:
- NEVER [prohibited approach]
- ALWAYS [required approach]
```

**Which patterns to document first:**
- Authentication / authorization
- API endpoint structure
- Database queries
- Error handling
- Form validation

**Tip:** Start with patterns you explain most often in code reviews.

---

### Step 4: Configure AI Agent (15 minutes)

Edit `CLAUDE.md`:

```markdown
# Claude Code Workflow

## Role

[Your preferred AI persona]

## CLI Commands

- Test: [your test command]
- Lint: [your lint command]
- Build: [your build command]

## Operational Loop

1. Read NEXT-TASKS.md
2. Reference PATTERNS.md
3. Implement with tests
4. Validate before committing

## Critical Rules

- [Security rules]
- [Data validation rules]
- [Prohibited patterns]
```

---

### Step 5: Test AI Integration (5 minutes)

Ask your AI assistant:

> "Read NEXT-TASKS.md and summarize what I am working on"

**Expected:** AI summarizes your current sprint accurately.

> "Implement [a feature from NEXT-TASKS.md] following PATTERNS.md"

**Expected:** AI generates code matching your documented patterns.

**If AI does not read the files automatically:**
- Claude Code: Files in root and `.github/` are auto-loaded
- GitHub Copilot: Edit `.github/copilot-instructions.md`
- Cursor: Symlink `CLAUDE.md` to `.cursorrules`

---

### Step 6: Enable Validation (15 minutes)

Add to your CI/CD pipeline:

<Tabs>
  <TabItem label="GitHub Actions">
    ```yaml
    # .github/workflows/validate.yml
    name: Validate Documentation

    on: [pull_request]

    jobs:
      validate:
        runs-on: ubuntu-latest
        steps:
          - uses: actions/checkout@v4
          - uses: actions/setup-node@v4
            with:
              node-version: 20
          - run: npx cortex-tms validate --strict
    ```
  </TabItem>

  <TabItem label="GitLab CI">
    ```yaml
    # .gitlab-ci.yml
    validate-docs:
      image: node:20
      script:
        - npx cortex-tms validate --strict
      only:
        - merge_requests
    ```
  </TabItem>

  <TabItem label="CircleCI">
    ```yaml
    # .circleci/config.yml
    version: 2.1
    jobs:
      validate:
        docker:
          - image: cimg/node:20.0
        steps:
          - checkout
          - run: npx cortex-tms validate --strict
    workflows:
      validate-docs:
        jobs:
          - validate
    ```
  </TabItem>
</Tabs>

**Now PRs fail if:**
- `NEXT-TASKS.md` exceeds 200 lines
- `PATTERNS.md` references non-existent files
- Documentation contradicts code

---

### Step 7: Establish Weekly Hygiene (10 minutes per week)

**Every week:**
1. Update `NEXT-TASKS.md` (mark completed tasks)
2. Archive completed tasks to `docs/archive/sprint-YYYY-MM.md`
3. Add new patterns to `PATTERNS.md` if they emerged

**Set a calendar reminder:**
- Friday afternoon (end of week cleanup)
- Monday morning (start of week planning)

**Tip:** Make this part of your weekly planning ritual.

---

## Frequently Asked Questions

### Can I adopt TMS incrementally?

**Yes.** Start with `NEXT-TASKS.md` and `CLAUDE.md` (30 minutes). Add other files as patterns emerge.

You do not need the full structure on day one.

---

### What if my team is skeptical about AI?

**TMS still provides value** without AI:
- Faster human onboarding (HOT tier gives immediate context)
- Documentation validation (prevents drift)
- Architectural decision tracking (ADRs)

But the ROI is much higher with AI usage.

**Strategy:** Start small (solo adoption), demonstrate results, advocate for team adoption.

---

### How do I convince my team to adopt TMS?

**Show ROI with numbers:**

1. **Measure current pain:**
   - How long does code review take? (time spent explaining patterns)
   - How long does onboarding take? (time to first PR)
   - How many pattern-violation bugs per month?

2. **Run a 2-week experiment:**
   - Set up TMS in a single repo
   - Track time saved in code review
   - Track AI code quality improvement

3. **Present results:**
   - "Code review time reduced from 60 min to 25 min per PR"
   - "AI-generated code acceptance rate increased from 40% to 80%"
   - "Onboarding time reduced from 2 weeks to 3 days"

**Teams adopt TMS when they see measurable time savings.**

---

### What if I am not sure about my patterns yet?

**Do not document patterns prematurely.**

TMS works best when patterns have stabilized. If you are still experimenting:
- Start with `NEXT-TASKS.md` only (track current work)
- Add `PATTERNS.md` later when you find yourself implementing the same thing twice
- Add `ARCHITECTURE.md` later when tech stack decisions are made

**Tip:** Document patterns on the second or third implementation, not the first.

---

### Can I use TMS for non-code projects?

**Yes, with adaptations.**

TMS principles apply to any knowledge work:
- **Writing**: Track current articles (NEXT-TASKS.md), style guide (PATTERNS.md)
- **Design**: Track current designs (NEXT-TASKS.md), design system (PATTERNS.md)
- **Research**: Track current experiments (NEXT-TASKS.md), methodology (PATTERNS.md)

The CLI is optimized for code projects, but the concepts are universal.

---

### What is the minimum team size for TMS?

**Technically, no minimum.** Solo developers benefit from TMS if they use AI heavily.

**Practically, ROI is highest at 3+ people** because knowledge transfer becomes critical at that size.

**Exception:** Solo developers with heavy context-switching benefit even with team size of 1.

---

## Next Steps

<CardGrid>
  <Card title="Quick Start" icon="rocket">
    Install Cortex TMS and scaffold your first governance structure in 5 minutes.

    [Get Started →](/getting-started/quick-start/)
  </Card>

  <Card title="vs. Traditional Documentation" icon="document">
    Learn how Cortex TMS differs from conventional docs and why enforcement matters.

    [Read Comparison →](/comparisons/vs-traditional-docs/)
  </Card>

  <Card title="vs. Docusaurus" icon="seti:config">
    Understand when to use TMS, Docusaurus, or both for your documentation strategy.

    [Read Comparison →](/comparisons/vs-docusaurus/)
  </Card>

  <Card title="Tiered Memory System" icon="star">
    Deep dive into the HOT/WARM/COLD architecture that optimizes AI performance.

    [Learn Concepts →](/concepts/tiered-memory/)
  </Card>
</CardGrid>

---

## Conclusion: Know Your Context

Cortex TMS is a powerful tool for AI governance and architectural enforcement. But it is not a universal solution.

**Use TMS if:**
- You use AI coding assistants heavily (40%+ of code)
- Your team is growing and needs governance
- You have architectural decisions that MUST be enforced
- You are tired of explaining the same patterns repeatedly

**Skip TMS if:**
- You are solo with no AI usage and no collaborators planned
- Your project is trivial or short-lived
- Your team is tiny (under 3) with daily communication
- You have regulatory requirements for specific doc formats

**The decision is not about project size.** It is about **governance needs** and **AI adoption**.

Small teams with heavy AI usage benefit more than large teams with no AI usage.

**Evaluate your context. Choose accordingly.**

<Aside type="tip" title="Pro Tip">
  When in doubt, start minimal (NEXT-TASKS.md + CLAUDE.md). Expand as you see value. You can always add more structure later, but starting too heavy creates friction.
</Aside>
