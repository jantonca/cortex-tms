# Ultra-Conservative MVP - Implementation Checklist

**Total Scope**: 10 hours over 3 weeks
**Start Date**: Week of 2026-02-02
**Approach**: Measure at each step, decide next phase based on results

---

## Week 1: Claim Audit (4 hours)

### Task: Remove Unverified Claims from README

**File**: `/home/jma/repos-ubuntu/github/cortex-tms/README.md`

#### Step 1: Identify Claims (30 min)
- [ ] Read README.md completely
- [ ] List all quantitative claims:
  - [ ] "X% reduction"
  - [ ] "Xx faster"
  - [ ] "Saves $X"
  - [ ] "Prevents/eliminates"
  - [ ] Any specific numbers
- [ ] Mark each as: VERIFIED (have data) or UNVERIFIED (no data)

#### Step 2: Remove Unverified Claims (1.5 hours)
- [ ] Remove or soften these specific claims:
  - [ ] "10x cheaper" â†’ Remove (this is model comparison)
  - [ ] "3-5x faster" â†’ Remove (no benchmarks)
  - [ ] "94% reduction" â†’ Remove (unrealistic scenario)
  - [ ] "Prevents hallucinations" â†’ Change to "Helps reduce pattern violations"
  - [ ] "Eliminates drift" â†’ Change to "Helps prevent drift"
  - [ ] Any other absolute claims ("always", "never", "guaranteed")

#### Step 3: Add Transparent Note (1 hour)
- [ ] Add measurement transparency section:
  ```markdown
  ## Measurement & Validation

  **Current Evidence**:
  Early internal measurements across ~47 development sessions suggest
  approximately 60-70% context reduction through tiered documentation
  organization.

  **Ongoing Work**:
  We're building a public benchmark suite to validate these findings
  rigorously across diverse projects and usage patterns.

  **Transparency**:
  Read our measurement methodology: [link to blog post]
  Track benchmark development: [link to FUTURE-ENHANCEMENTS.md]

  We're committed to honest, data-driven claims. Until benchmarks are
  complete, treat these figures as early indicators, not guarantees.
  ```

#### Step 4: Review & Test (1 hour)
- [ ] Read revised README start to finish
- [ ] Check tone: Honest? Humble? Confident without overclaiming?
- [ ] External review: Ask 2-3 people "Does this feel trustworthy?"
- [ ] Fix any remaining absolute claims

#### Step 5: Commit (15 min)
- [ ] Git branch: `git checkout -b docs/claim-audit-v3.2.1`
- [ ] Commit: `git commit -m "docs: remove unverified claims, add transparent measurement note"`
- [ ] Push: `git push origin docs/claim-audit-v3.2.1`
- [ ] Create PR or merge directly (per CLAUDE.md protocol)

**Deliverable**: README with honest, qualified claims only

---

## Week 2-3: Phase 1 MVP (6 hours)

### Task 1.1: Next Steps After Init (2 hours)

**File**: `/home/jma/repos-ubuntu/github/cortex-tms/src/commands/init.ts`

#### Implementation (1.5 hours)
- [ ] Read existing success message (line ~450-500 range)
- [ ] Replace with:
  ```typescript
  console.log(chalk.green('\nâœ… Cortex TMS Initialized!\n'));

  console.log(chalk.cyan('ðŸš€ Quick Start (One Golden Path):\n'));
  console.log(chalk.gray('  1. Validate your setup:'));
  console.log(`     ${chalk.bold('cortex-tms validate')}\n`);

  console.log(chalk.gray('  2. Start your AI session:'));
  console.log(`     ${chalk.bold('cortex-tms prompt init-session')}`);
  console.log(chalk.gray('     (Copy output, paste into Claude Code/Cursor/Copilot)\n'));

  console.log(chalk.gray('  3. See your context savings:'));
  console.log(`     ${chalk.bold('cortex-tms status')}\n`);

  console.log(chalk.cyan('ðŸ’¡ New to TMS?'));
  console.log(`   Read: ${chalk.underline('docs/guides/START-HERE.md')}\n`);

  console.log(chalk.cyan('ðŸ“š Full docs:'));
  console.log(`   ${chalk.underline('https://cortex-tms.org')}\n`);
  ```

#### Test (30 min)
- [ ] Run `cortex-tms init --scope nano --force` in test directory
- [ ] Verify message appears
- [ ] Check: Is it < 15 lines? Clear? Actionable?
- [ ] User test: Can someone follow these steps?

**Deliverable**: Clear next-steps message after init

---

### Task 1.2: START-HERE.md Guide (2 hours)

**File**: `/home/jma/repos-ubuntu/github/cortex-tms/docs/guides/START-HERE.md`

#### Implementation (1.5 hours)
- [ ] Create file if doesn't exist
- [ ] Write ONE recommended path (target: 5 min read):
  ```markdown
  # Start Here: 5-Minute Quick Start

  **Goal**: Get productive with Cortex TMS in 5 minutes

  ## The Golden Path (Recommended for 90% of users)

  ### Step 1: Initialize (30 seconds)
  ```bash
  cortex-tms init --scope standard
  ```

  This creates 9 documentation files in your project.

  ### Step 2: Validate (30 seconds)
  ```bash
  cortex-tms validate
  ```

  This checks your setup. You'll see some warnings about placeholders - that's normal.

  ### Step 3: Start AI session (2 minutes)
  ```bash
  cortex-tms prompt init-session
  ```

  Copy the output and paste it into:
  - Claude Code (opens automatically)
  - Cursor AI (Cmd+L / Ctrl+L)
  - GitHub Copilot Chat

  Your AI will now focus on the HOT tier (active sprint + patterns)
  instead of trying to read your entire codebase at once.

  ### Step 4: See your savings (30 seconds)
  ```bash
  cortex-tms status
  ```

  Look for "Context Reduction" - this shows how much context you're saving.

  ### Step 5: Code! (rest of your day)

  Use your AI tool normally. It now has:
  - âœ… Focused context (HOT tier only)
  - âœ… Your active sprint tasks
  - âœ… Your code patterns
  - âœ… No archived files or noise

  ## What's Next?

  - **Fill placeholders**: Run `cortex-tms validate` and fix warnings
  - **Update tasks**: Edit NEXT-TASKS.md with your actual sprint
  - **Customize patterns**: Edit docs/core/PATTERNS.md
  - **Learn more**: https://cortex-tms.org

  ## Other Paths (Advanced)

  - **Existing project**: See [MIGRATION.md](MIGRATION.md) (coming soon)
  - **Custom setup**: See [CUSTOMIZATION.md](CUSTOMIZATION.md)
  - **Team setup**: See [TEAM-SETUP.md](TEAM-SETUP.md)

  ---

  **Questions?** Open a [GitHub Discussion](https://github.com/cortex-tms/cortex-tms/discussions)
  ```

#### Test (30 min)
- [ ] Read aloud (is it <5 min?)
- [ ] Follow steps yourself in new project
- [ ] User test: Can beginner follow it?
- [ ] Check all links work

**Deliverable**: 5-minute quick start guide

---

### Task 1.5: Token Savings Visible (2 hours)

**File**: `/home/jma/repos-ubuntu/github/cortex-tms/src/commands/status.ts`

#### Implementation (1.5 hours)
- [ ] Find default status output (not `--tokens` mode)
- [ ] Add new section after "Quick Actions":
  ```typescript
  // After Quick Actions section
  if (!options.tokens) {
    // Run quick token estimate
    const tokenStats = await runQuickTokenEstimate();

    console.log(chalk.bold('\nðŸ’° Context Savings (Estimate)'));
    console.log(`  ${chalk.cyan('HOT tier (active):')} ${formatTokens(tokenStats.hot)} tokens`);
    console.log(`  ${chalk.cyan('Full repository:')} ${formatTokens(tokenStats.total)} tokens`);
    console.log(`  ${chalk.green('Reduction:')} ${chalk.bold(formatPercent(tokenStats.reduction))}`);
    console.log(chalk.gray('\n  ðŸ’¡ Run cortex-tms status --tokens for detailed breakdown'));
  }
  ```

- [ ] Implement `runQuickTokenEstimate()`:
  ```typescript
  async function runQuickTokenEstimate(): Promise<TokenStats> {
    // Use existing token-counter with simplified output
    // Cache result for 5 minutes to avoid re-analyzing
    // Return { hot, total, reduction }
  }
  ```

- [ ] Add caching (5 min TTL):
  ```typescript
  const CACHE_TTL = 5 * 60 * 1000; // 5 minutes
  let cachedStats: { data: TokenStats; timestamp: number } | null = null;
  ```

#### Test (30 min)
- [ ] Run `cortex-tms status` (without --tokens)
- [ ] Verify savings shown
- [ ] Check that estimated reduction is plausible and roughly matches `status --tokens`
- [ ] Run again immediately (should use cache)
- [ ] Wait 6 min, run again (should re-analyze)

**Deliverable**: Token savings in default status output

---

## Week 4: Measure & Decide (ongoing)

### Metrics to Track

#### Quantitative
- [ ] Time-to-first-value: Use /usr/bin/time or manual timing
  - Target: 20min â†’ 10-15min
  - Test with 5+ new users
- [ ] Tutorial completion: Track who finishes START-HERE.md
  - Target: >60% completion
- [ ] `cortex-tms status` usage: Check npm telemetry (if available)
  - Target: Used within first 10 min by >70% of users

#### Qualitative
- [ ] GitHub Discussions feedback
  - Post: "We just shipped v3.3.0 with better onboarding. Feedback?"
  - Target: >70% positive sentiment
- [ ] Reddit/HN comments (if posted there)
- [ ] Direct user interviews (3-5 people)
  - Questions:
    - "What was confusing?"
    - "What helped most?"
    - "What should we fix next?"

### Decision Framework

**If time-to-first-value improved significantly (>40%)**:
â†’ Success! Consider migration tooling next (Phase 2 MVP)

**If time-to-first-value improved slightly (20-40%)**:
â†’ Partial success. Do more Phase 1 tasks (1.3, 1.4) or refine existing

**If time-to-first-value didn't improve (<20%)**:
â†’ Rethink approach. User interviews to understand why

**If feedback requests migration tools**:
â†’ Consider Phase 2 MVP

**If feedback requests benchmarks/proof**:
â†’ Consider Phase 3 benchmarks

**If feedback is positive but wants more features**:
â†’ Resist scope creep. Iterate on core UX first

---

## Git Protocol

### Branch Strategy
- `docs/claim-audit-v3.2.1` â†’ Claim audit only
- `feat/onboarding-mvp-v3.3.0` â†’ Phase 1 MVP (tasks 1.1, 1.2, 1.5)

### Commit Messages
```bash
# Week 1
git commit -m "docs: remove unverified claims, add transparent measurement note

Removed quantitative claims without benchmark data:
- 10x cheaper (model comparison, not TMS)
- 3-5x faster (no benchmarks yet)
- 94% reduction (unrealistic scenario)
- Prevents hallucinations (conflates concepts)

Added transparent measurement note:
- Early internal measurements (~47 sessions)
- Building public benchmark suite
- Link to measurement methodology

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"

# Week 2-3
git commit -m "feat(ux): add next steps after init, START-HERE guide, token savings

Task 1.1: Show golden path after init (validate â†’ prompt â†’ code)
Task 1.2: Create 5-minute START-HERE.md quick start guide
Task 1.5: Display context savings in default status output

Time-to-first-value target: 20min â†’ 10-15min

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Success Criteria

### Week 1 Complete When:
- [ ] README has no unverified quantitative claims
- [ ] Transparent measurement note added
- [ ] External reviewer says "feels honest"
- [ ] Committed to main

### Week 2-3 Complete When:
- [ ] Init shows clear next steps
- [ ] START-HERE.md exists and is <5 min read
- [ ] Status shows token savings (conservative numbers)
- [ ] 5 users test successfully (get productive in <15 min)
- [ ] Committed to main

### Week 4 Complete When:
- [ ] Metrics collected (10+ user data points)
- [ ] Feedback gathered (GitHub, Reddit, interviews)
- [ ] Decision made: What's next phase?
- [ ] Documented in NEXT-TASKS.md

---

## Risk Mitigation

### Risk: Week 1 claim audit makes README feel too weak
**Mitigation**: Keep qualitative value strong, add "building benchmarks" note

### Risk: Week 2-3 features don't reduce time-to-first-value enough
**Mitigation**: User test early (day 1 of Week 2), pivot if needed

### Risk: Week 4 feedback says "need migration tools NOW"
**Mitigation**: Have Phase 2 MVP ready to start (already designed)

### Risk: Scope creep during implementation
**Mitigation**: Strict scope - ONLY 4 tasks. Write down tempting features for later

---

## Questions to Resolve During Implementation

1. Should START-HERE.md be in `docs/guides/` or root `docs/`?
   - Recommendation: `docs/guides/` (keeps root clean)

2. Should token savings be in ALL status output or just when TTY?
   - Recommendation: TTY only (avoid noise in CI/CD)

3. Should we create GitHub Discussion post now or after v3.3.0?
   - Recommendation: After v3.3.0 (show, don't tell)

4. Should claim audit be v3.2.1 or part of v3.3.0?
   - Recommendation: v3.2.1 separate (build trust first)

---

## Next Immediate Action

**START HERE**:
1. âœ… Read this checklist completely
2. â³ Create `docs/claim-audit-v3.2.1` branch
3. â³ Open README.md
4. â³ Start Week 1, Step 1: Identify claims

**Estimated completion**:
- Week 1: 4 hours â†’ 2-3 calendar days
- Week 2-3: 6 hours â†’ 3-4 calendar days
- Week 4: Ongoing â†’ 1 week to collect data

**Total**: ~2-3 weeks calendar time, 10 hours focused work

---

**Ready to start Week 1!** ðŸŽ¯
